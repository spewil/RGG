{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Isolates\n",
    "\n",
    "Since every loose node will be unmatched, so if we adjust the $n_D$ value by the number of loose nodes, we have a better idea of the controllability of the graph's clusters. Testing this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "from network_generation import generation as ng\n",
    "import experiment as ex\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ER_nD(kappa, plot=False):\n",
    "        \n",
    "    # make sure this is a float!\n",
    "    z0 = float(kappa/2)\n",
    "    w1irange = np.arange(0,1,.01)\n",
    "    w1o = lambda x: np.exp(-z0*np.exp(-z0*x))\n",
    "    w1i = lambda y: -(1/z0)*np.log((1/z0)*np.log(1/y))\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(w1irange,[w1o(i) for i in w1irange])\n",
    "        plt.plot(w1irange,w1irange,'k-')\n",
    "        \n",
    "        w1o = lambda x: np.exp(-z0*np.exp(-z0*x))\n",
    "    w1i = lambda y: -(1/z0)*np.log((1/z0)*np.log(1/y))\n",
    "    \n",
    "    # BABY NEWTON METHOD \n",
    "    xold = 0.5\n",
    "    yold = 0.5\n",
    "    check = 100\n",
    "    while abs(check)>0.001:\n",
    "\n",
    "        # move up\n",
    "        ynew = w1o(xold)\n",
    "        # move right \n",
    "        xnew = ynew\n",
    "        \n",
    "        if plot: \n",
    "            plt.plot((xold,xold),(yold,ynew),'r-')\n",
    "            plt.plot((xold,xnew),(ynew,ynew),'r-')\n",
    "\n",
    "        # compute check \n",
    "        check = xold - xnew \n",
    "\n",
    "        # update for next iteration\n",
    "        xold = xnew \n",
    "        yold = ynew\n",
    "\n",
    "    w1 = xnew \n",
    "    w2 = 1 - np.exp(-z0*w1)\n",
    "    nD = w1 - w2 + z0*w1*(1-w2)\n",
    "\n",
    "    return nD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "kappa_range = [1,3,5,10,15,20]\n",
    "n = 100\n",
    "\n",
    "ERE = ex.ERExperiment(kappa_range, n, find_scaling=False)\n",
    "plt.errorbar(ERE.mean_degree_list,ERE.mean_nD_list,fmt='ro',markersize=3,ecolor='r',xerr=ERE.std_degree_list,yerr=ERE.std_nD_list)\n",
    "\n",
    "print 'ER sim with isolates done'    \n",
    "\n",
    "ERE = ex.ERExperiment(kappa_range, n, find_scaling=False, remove_isolates=True)\n",
    "plt.errorbar(ERE.mean_degree_list,ERE.mean_nD_list,fmt='go',markersize=3,ecolor='g',xerr=ERE.std_degree_list,yerr=ERE.std_nD_list)\n",
    "\n",
    "print 'ER sim with isolates done'    \n",
    "    \n",
    "# plot theory \n",
    "kappa_ranget = np.arange(.1,22,.01)\n",
    "nD_list = []\n",
    "for kappa in kappa_ranget:\n",
    "    nD_list.append(find_ER_nD(kappa))\n",
    "plt.plot(kappa_ranget,nD_list,'k--')    \n",
    "\n",
    "print 'ER theory done'\n",
    "\n",
    "plt.legend(['isolates','no isolates','theory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# load and plot ER data \n",
    "kappa_range = [1,3,5,10,15,20]\n",
    "n = 1000\n",
    "\n",
    "ERE = ex.ERExperiment(kappa_range, n, find_scaling=False)        \n",
    "plt.errorbar(ERE.mean_degree_list,ERE.mean_nD_list,fmt='ro',markersize=3,ecolor='r',xerr=ERE.std_degree_list,yerr=ERE.std_nD_list)\n",
    "\n",
    "print 'ER sim done'    \n",
    "    \n",
    "# plot theory \n",
    "kappa_ranget = np.arange(.1,22,.01)\n",
    "nD_list = []\n",
    "for kappa in kappa_ranget:\n",
    "    nD_list.append(find_ER_nD(kappa))\n",
    "plt.plot(kappa_ranget,nD_list,'k--')    \n",
    "\n",
    "print 'ER theory done'\n",
    "\n",
    "## SOLID \n",
    "d_range = [2,3,6,9]\n",
    "for d in d_range:\n",
    "    RGGE = ex.RGGExperiment(kappa_range, n, d, shortcut_prob=0, boundary='s',find_scaling=False)\n",
    "    plt.errorbar(RGGE.mean_degree_list, RGGE.mean_nD_list, fmt='none', yerr=RGGE.std_nD_list, xerr=RGGE.std_degree_list)\n",
    "    print str(d) +'th dimension done'\n",
    "    \n",
    "plt.title('$k$ vs. $n_D$ solid BC')\n",
    "plt.xlabel('Mean Average Degree $\\\\langle{k}\\\\rangle$')\n",
    "plt.ylabel('Fraction of Driver Nodes $n_D$')\n",
    "legend_string = ['d='+str(d) for d in d_range]\n",
    "legend_string.append('ER Theory')\n",
    "legend_string.append('ER Sim')\n",
    "legend_string.reverse()\n",
    "plt.legend(legend_string)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/k_nD_s_N' + str(n) + '.eps',dpi=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
